{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOs+9ktCiemOC1gyOlsr7t/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Olivermugambi/MaximumLikelihoodEstimates/blob/main/Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformers\n"
      ],
      "metadata": {
        "id": "U-F61YYgKTvg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divided into inputs and outputs module"
      ],
      "metadata": {
        "id": "qe9U6ccWKZAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math"
      ],
      "metadata": {
        "id": "c6VRcM6eKj_S"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Inputs:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def input_embedding(self):\n",
        "    pass\n",
        "\n",
        "  def positional_encoding(self):\n",
        "    pass\n",
        "\n",
        "  def multi_head_attention(self):\n",
        "    pass\n",
        "\n",
        "  def add_and_norm(self):\n",
        "    pass\n",
        "\n",
        "  def feed_forward(self):\n",
        "    pass\n",
        "\n",
        "  def scaled_dot_product(self, queries, keys, values):\n",
        "    keys_dim = len(keys)\n",
        "    dot_prod_list = []\n",
        "    if(len(queries) == keys_dim):\n",
        "      for i in range(keys_dim):\n",
        "          dot_prod_list.append(queries[i] * keys[i] / math.sqrt(keys_dim))\n",
        "      dot_prod_list = self.softmax(dot_prod_list)\n",
        "      return self.dot_prod(dot_prod_list, values)\n",
        "    else:\n",
        "      pass \n",
        "\n",
        "  def softmax(self, values):\n",
        "    list_sum = sum(values)\n",
        "    softmax_values = []\n",
        "    for i in range(len(values)):\n",
        "      softmax_values.append(math.exp(values[i])/math.exp(list_sum))\n",
        "    return softmax_values\n",
        "\n",
        "  def dot_prod(self, list1, list2):\n",
        "    #parallelization could help here\n",
        "    res_list = []\n",
        "    if(len(list1) == len(list2)):\n",
        "      for i in range(len(list1)):\n",
        "        res_list.append(list1[i] * list2[i])\n",
        "      return res_list\n",
        "    else:\n",
        "      pass\n"
      ],
      "metadata": {
        "id": "8txN_6QbKtzW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}